\documentclass[openany]{book}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{booktabs}
\usepackage{caption} 
\usepackage{multirow}
\usepackage{fancyhdr}
\usepackage{subfiles}
\usepackage{subfig}
\usepackage{float}
\usepackage{hyperref}
\hypersetup{pdftex,colorlinks=true,allcolors=black}
\usepackage{hypcap}
% \renewcommand{\thesubfigure}{\Alph{subfigure}}



\renewcommand{\headrulewidth}{0pt}
\pagestyle{fancy}
\fancyhf{}
% \fancyfoot[LE,RO]{\thepage}
\fancyhead[RO]{\nouppercase{\thepage}}
\fancyhead[RE]{\nouppercase{\thepage}}
\fancyhead[LE]{\slshape\nouppercase{\rightmark}}
\fancyhead[LO]{\slshape\nouppercase{\rightmark}}


\captionsetup[table]{skip=5pt}
\captionsetup{format=plain, font=small, labelfont=bf}

\makeatletter
% \renewcommand{\@chapapp}{}% Not necessary...
\newenvironment{chapquote}[2][2em]
  {\setlength{\@tempdima}{#1}%
   \def\chapquote@author{#2}%
   \parshape 1 \@tempdima \dimexpr\textwidth-2\@tempdima\relax%
   \itshape}
  {\par\normalfont\hfill--\ \chapquote@author\hspace*{\@tempdima}\par\bigskip}
\makeatother


\renewcommand{\baselinestretch}{1.5}

\title{\textbf{Learning Depth and Visual Odometry From Light Fields} \\
\large School of Aerospace, Mechanical and Mechatronic Engineering \\
\large The University of Sydney}
\date{May, 2020}

\author{Joseph Daniel}

\begin{document}

\frontmatter

\chapter*{Statement of Contribution}

\begin{itemize}
  \item I carried out the literature review in order to evaluate existing algorithms and approaches.
  \item I authored the data acquisition software and collected the dataset of light field video used in this work. 
  \item With the help of my supervisor Dr. Donald Dansereau, I designed and implemented the novel algorithms described in this work.
  \item I augmented existing code from Zhou \textit{et al.} \cite{zhou2017unsupervised}, authoring custom components for data-loading, loss computations, and performing inference.
  \item I carried out the experiments using the proposed algorithm.
  \item I authored the functions for analysing experimental results, and conducted the analysis myself, with advice provided by my supervisor. 
  \item I carried out the discussion and conclusion, which are my own, influenced by discussion with my supervisor.
\end{itemize}


\textbf{Joseph Thomas Daniel} 

May 26th, 2020

\maketitle


\chapter*{Abstract}

The meteoric rise of mobile robotics has seen traditionally difficult-to-navigate environments like the home, the road and the ocean, become standard operating environments for autonomous machines. This rapid advancement has culminated in an increasing need for accurate robotic navigation, where the pinnacle of autonomy is the ability to operate adaptively in unconstrained environments. Central to this capability is the ability to perceive motion - a task that has recently drawn considerable attention from those in the computer vision community and given rise to a family of algorithms called \textit{visual odometry}. 

The primary contribution of this work is a novel, data-driven pipeline for visual odometry, which combines recent successes in plenoptic imaging with the pattern recognition capabilities of convolutional networks. Notably, we formulate our algorithm as an \textit{unsupervised} learning problem, meaning neither ground-truth odometry, nor depth is used to train our pipeline. The self-supervising nature of our algorithm equips it with a robustness to effects like thermal expansion, and shock - effects which are all too common in mobile robotics, and likely to render equipment calibration invalid. Being self-supervised, our algorithm is capable of adapting and learning from experience, even whilst operating in-situ, building resilience to these destabilising effects.

% While our algorithm is indeed data-driven, we the proposed pipeline is unsupervised, meaning ground truth data which is typically expensive and time-consuming to acquire, is not required for the algorithm to function. Furthermore, the unsupervised nature of the algorithm endows it with a robustness to the inconvenient, calibration-wrecking effects that field robotics are all-too-frequently subjected to, such as thermal expansion and shock. 

% The proposed algorithm is trained and validated on a dataset which was collected over the course of this project. A robotic arm with a known kinematic model is used for data-collection, providing ground truth trajectory data for validation. While the algorithm does not require this ground truth data to train on, it is nevertheless a useful byproduct of the data-acquisition process, allowing us to perform a healthy validation study of the proposed model.

We train and validate our algorithm on a dataset, collected and annotated as part of this thesis project. A robotic arm with a known kinematic model is used to acquire our dataset, providing valuable ground-truth data for validation.

Finally, we compare our proposed pipeline to two existing families of visual odometry algorithms. The first is a group of algorithms that directly model the geometry of multi-view imaging, solving directly for ego-motion using closed-form solutions. The second family uses data-driven approaches, but unlike this work they do not harness the power of plenoptic imaging. In doing so, we demonstrate the power of plenoptic imaging as a novel imaging modality for robotics, in terms of accuracy, computational convenience and adaptability.


\chapter*{Acknowledgements}
I would like to express my gratitude to my supervisor, Dr. Donald Dansereau, for his guidance throughout this thesis project. His encouragement and motivation has inspired my interest in robotics and computational imaging, and his unremitting thoughtfulness has at all times kept me thinking critically. My thanks also to my colleagues in the school of AMME, who have provided consistently valuable feedback in our weekly roundtable discussions and made this thesis all the more enjoyable. 

I would like to also acknowledge my family and friends who have supported me during this thesis, whether through their heartening encouragement or simple acts of homemade food delivery that kept me from burning out. Finally, a special thanks to Josephine for her patience and support in this time of physical isolation - she has consistently shown her compassion and kindness, even though the apartment we share certainly wasn't designed for two to be working from home.

\tableofcontents
\listoffigures
\listoftables

\mainmatter
\subfile{chap1_intro.tex}
\subfile{chap2_background.tex}
\subfile{chap3_lit.tex}
\subfile{chap4_methods.tex}
\subfile{chap5_results.tex}
\subfile{chap6_discussion.tex}
\subfile{chap7_conclusion.tex}


\newpage

%\newpage
\bibliographystyle{plain}
\bibliography{bibliography.bib}

\end{document}
